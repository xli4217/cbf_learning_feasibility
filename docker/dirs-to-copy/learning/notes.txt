- Test env cmd
  - python ${LEARNING_PATH}learning/experiments.py --max_episode_timesteps 10 --rollout_batch_size 2  

- Training cmd
  - python ${LEARNING_PATH}learning/experiments.py --max_episode_timesteps 50 --max_itr 500 --policy_lr 0.005 --nb_training_epoches 5 --rollout_batch_size 10 --value_loss_coef 0.4 --minibatch_size 128 --use_preprocessors True --update_preprocessors True --save_preprocessors True
  
- Hyperparam tuning cmd
  - python ${LEARNING_PATH}learning/experiments.py --max_episode_timesteps 50 --rollout_batch_size 10 --use_preprocessors True --update_preprocessors True --save_preprocessors True --mode hyperparam_tuning

- Deploy cmd
  - python ${LEARNING_PATH}learning/experiments.py --exp_name cloud/rlfps-small/test --hyperparam_dir seed0 --itr 100 --nb_trial_runs 10 --use_preprocessors True --mode deploy --sampler_traj False


- flip switch on goal pose: 0.757, -1.83, 0.76 (world)

- TODO
  - entropy always increasing

- Done
  - value loss too large (pytorch MSELoss() implementation has bug, not giving right value in value_loss())
  - ball jumps (after reset, getObjectPosition still reads old data - button_vel, added a loop in reset until button_vel close to zero is read)
  - explained_var sometimes NaN (given batch of 1, which happens to be rollout_batch_data_size % minibatch_size and the last minibatch has a small number of samples)
  - deploy doesn't work (forgot to use and restore state_preprocessor in deploy())

